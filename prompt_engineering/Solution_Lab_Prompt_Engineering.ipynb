{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpT3x5hdIMoE"
      },
      "source": [
        "# Prompt Engineering\n",
        "\n",
        "### Author: Sharon Zhou <<sharonz@cs.stanford.edu>>. CS Dept Faculty, Stanford University.\n",
        "\n",
        "### This notebook lives [here](https://colab.research.google.com/drive/1P4W-V_JDUs1bOm6c5Bfn6aG5HtDx4QZm).\n",
        "\n",
        "#### In this notebook, you'll get change and play with the data that is inputed to LLMs in a programmatic way.\n",
        "\n",
        "#### _Goal: See how even small amounts of data can make an LLM much more useful!_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "woS3HNl5V-Vd"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# @title Setup: Authenticate with Google & install the open-source [PowerML library](https://pypi.org/project/powerml-app/0.0.35/) to use LLMs easily\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# %%capture\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auth\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauthenticate_powerml\u001b[39m():\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# @title Setup: Authenticate with Google & install the open-source [PowerML library](https://pypi.org/project/powerml-app/0.0.35/) to use LLMs easily\n",
        "# %%capture\n",
        "\n",
        "from google.colab import auth\n",
        "import requests\n",
        "\n",
        "def authenticate_powerml():\n",
        "  auth.authenticate_user()\n",
        "  gcloud_token = !gcloud auth print-access-token\n",
        "  powerml_token_response = requests.get('https://api.staging.powerml.co:5002/auth/verify_gcloud_token?token=' + gcloud_token[0])\n",
        "  return powerml_token_response.json()['token']\n",
        "\n",
        "token = authenticate_powerml()\n",
        "!pip install powerml-app==0.0.41\n",
        "\n",
        "config = {\"powerml\": { \"key\": token, \"url\": \"https://api.staging.powerml.co\" }}\n",
        "\n",
        "# print('Ready to play with LLMs!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nN3m31TZVH2"
      },
      "source": [
        "### Scenario\n",
        "\n",
        "You have a lot of email you have to write for the different extracurriculars: movie, running, and math clubs. So, you want to use an LLM to help you write them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtDJALVjITTG"
      },
      "source": [
        "\n",
        "### Exercise 1\n",
        "\n",
        "You have the following code written, so your LLM can write emails for all your clubs. But it writes a random email. You have no control over what the subject of them will be.\n",
        "\n",
        "**Your task: Adjust the context to enable you to specify the subject of the email.**\n",
        "\n",
        "_Goal: Learn how to build reusable contexts/prompts!_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AqV-F9jQJ0G"
      },
      "outputs": [],
      "source": [
        "from powerml import LLM, ContextTemplate\n",
        "\n",
        "# Build a template for giving context to your LLM; TODO: change the context to take in any subject\n",
        "context = \"Write an email for the {{club_name}} club.\" # double curly braces indicate a variable\n",
        "\n",
        "# Specify the variables in the context as arguments\n",
        "# Helpful reference when you have more arguments **hint**\n",
        "args=[\"club_name\"]\n",
        "\n",
        "# Instantiate the context template\n",
        "template = ContextTemplate(context, args)\n",
        "\n",
        "# Instantiate your LLM\n",
        "llm = LLM(config)\n",
        "\n",
        "# Fit your LLM to the context\n",
        "llm.fit(template)\n",
        "\n",
        "my_club_names = ['movie', 'running', 'math']\n",
        "for my_club_name in my_club_names:\n",
        "  # Run your LLM, looping through your different clubs\n",
        "  output = llm.predict(club_name=my_club_name)\n",
        "  print(output)\n",
        "  print(\"--------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yermXzWqvOrU"
      },
      "outputs": [],
      "source": [
        "# SOLUTION\n",
        "from powerml import LLM, ContextTemplate\n",
        "\n",
        "# Build a template for giving context to your LLM\n",
        "context = \"Write an email about {{subject}} for the {{club_name}} club.\" # double curly braces indicate a variable\n",
        "\n",
        "# Specify the variables in the context as arguments\n",
        "args=[\"subject\", \"club_name\"]\n",
        "\n",
        "# Instantiate the context template\n",
        "template = ContextTemplate(context, args)\n",
        "\n",
        "# Instantiate your LLM\n",
        "llm = LLM(config)\n",
        "\n",
        "# Fit your LLM to the context\n",
        "llm.fit(template)\n",
        "\n",
        "my_club_names_subjects = {\n",
        "    'movie': ['recruiting new members', 'the new harry potter fan fiction indie movie'],\n",
        "    'running': ['the team winning the meet', 'practice being still on despite the blizzard'],\n",
        "    'math': ['competition practice', 'electing a new president for next semester']\n",
        "}\n",
        "\n",
        "for my_club_name, subjects in my_club_names_subjects.items():\n",
        "  # Run your LLM, looping through your different clubs and subjects for them\n",
        "  for subject in subjects:\n",
        "    print(f'Email for {my_club_name} club about {subject}')\n",
        "    output = llm.predict(subject=subject, club_name=my_club_name)\n",
        "    print(output)\n",
        "    print(\"\\n--------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSU80AVATKnx"
      },
      "source": [
        "### Exercise 2\n",
        "The emails you're seeing don't sound like you. You sound better, funnier, or at least more like _you_! Good thing you have a few examples of emails you've written before for each club.\n",
        "\n",
        "**Your task: Given your past emails (provided for you), build a context template to include your past emails and fit a new LLM. Run and compare results.**\n",
        "\n",
        "_Goal: Observe the impact of more data._\n",
        "\n",
        "How does it do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qks1Se35n0ZO",
        "outputId": "78828fb6-edcc-4267-e0b4-d0bfd95ecbd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got all the emails!\n"
          ]
        }
      ],
      "source": [
        "# @markdown #### Setup: Fetch email files\n",
        "\n",
        "!wget -q -O \"movie_club.txt\" \"https://drive.google.com/uc?export=download&id=1dWKvcCIp-XwNBZ6heb5k2Y1tbdPl3WTE\"\n",
        "!wget -q -O \"running_club.txt\" \"https://drive.google.com/uc?export=download&id=1SxeE-0XP4ggjUNYwMD3VQlm_idCHoG9G\"\n",
        "!wget -q -O \"math_club.txt\" \"https://drive.google.com/uc?export=download&id=12z3EuOauuYc4Y9tdDGENs-_2wmvyErmv\"\n",
        "\n",
        "print('Got all the emails!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Nis3KpvfTJjw"
      },
      "outputs": [],
      "source": [
        "with open('movie_club.txt', 'r') as f:\n",
        "  past_movie_club_emails = f.read()\n",
        "with open('running_club.txt', 'r') as f:\n",
        "  past_running_club_emails = f.read()\n",
        "with open('math_club.txt', 'r') as f:\n",
        "  past_math_club_emails = f.read()\n",
        "\n",
        "# TODO (same code as above, without your changes for subject in Exercise 1)\n",
        "context = \"Write an email for the {{club_name}} club.\"\n",
        "args=[\"club_name\"]\n",
        "template = ContextTemplate(context, args)\n",
        "\n",
        "llm = LLM(config)\n",
        "llm.fit(template)\n",
        "\n",
        "my_club_names = ['movie', 'running', 'math']\n",
        "for my_club_name in my_club_names:\n",
        "  output = llm.predict(club_name=my_club_name)\n",
        "  print(output)\n",
        "  print(\"--------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jzWrcdrxmR1"
      },
      "outputs": [],
      "source": [
        "# SOLUTION\n",
        "with open('movie_club.txt', 'r') as f:\n",
        "  past_movie_club_emails = f.read()\n",
        "with open('running_club.txt', 'r') as f:\n",
        "  past_running_club_emails = f.read()\n",
        "with open('math_club.txt', 'r') as f:\n",
        "  past_math_club_emails = f.read()\n",
        "\n",
        "context = \"{{past_emails}}\\n\\nBased on the tone of past emails, write an email about {{subject}} for the {{club_name}} club.\" # double curly braces indicate a variable\n",
        "args=[\"past_emails\", \"subject\", \"club_name\"]\n",
        "template = ContextTemplate(context, args)\n",
        "\n",
        "llm = LLM(config)\n",
        "llm.fit(template)\n",
        "\n",
        "my_clubs_info = [\n",
        "    {\n",
        "      'name': 'movie',\n",
        "      'subjects': ['recruiting new members', 'the new harry potter fan fiction indie movie'],\n",
        "      'past_emails': past_movie_club_emails\n",
        "    },\n",
        "    {\n",
        "      'name': 'running',\n",
        "      'subjects': ['the team winning the meet', 'practice being still on despite the blizzard'],\n",
        "      'past_emails': past_running_club_emails\n",
        "    },\n",
        "    {\n",
        "      'name': 'math',\n",
        "      'subjects': ['competition practice', 'electing a new president for next semester'],\n",
        "      'past_emails': past_math_club_emails\n",
        "    }\n",
        "]\n",
        "\n",
        "for club in my_clubs_info:\n",
        "  my_club_name = club['name']\n",
        "  subjects = club['subjects']\n",
        "  past_emails = club['past_emails']\n",
        "\n",
        "  # Run your LLM, looping through your different clubs and subjects for them\n",
        "  for subject in subjects:\n",
        "    print(f'Email for {my_club_name} club about {subject}')\n",
        "    output = llm.predict(past_emails=past_emails, subject=subject, club_name=my_club_name)\n",
        "    print(output)\n",
        "    print(\"\\n--------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK5SFggfXUso"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "So you think you're funny and you prize how funny you are. But what if you can get the LLM to make you funnier?\n",
        "\n",
        "**Your task: Engineer the prompt such that you can sound funnier than you.**\n",
        "\n",
        "_Goal: Play with the model, and see where it's easy to manipulate and where it isn't. And that it is not always intuitive._\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxKl_zy0XUGj"
      },
      "outputs": [],
      "source": [
        "# TODO (same code as Exercise 2 to get you started, without your changes)\n",
        "\n",
        "with open('movie_club.txt', 'r') as f:\n",
        "  past_movie_club_emails = f.read()\n",
        "with open('running_club.txt', 'r') as f:\n",
        "  past_running_club_emails = f.read()\n",
        "with open('math_club.txt', 'r') as f:\n",
        "  past_math_club_emails = f.read()\n",
        "\n",
        "context = \"Write an email for the {{club_name}} club.\"\n",
        "args=[\"club_name\"]\n",
        "template = ContextTemplate(context, args)\n",
        "\n",
        "llm = LLM(config)\n",
        "llm.fit(template)\n",
        "\n",
        "my_club_names = ['movie', 'running', 'math']\n",
        "for my_club_name in my_club_names:\n",
        "  output = llm.predict(club_name=my_club_name)\n",
        "  print(output)\n",
        "  print(\"--------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylq_5zFJzuVX"
      },
      "source": [
        "There are many right answers, so don't worry if this doesn't match your completely! Humor is subjective, after all :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qePwMOfozZeQ"
      },
      "outputs": [],
      "source": [
        "# SOLUTION\n",
        "\n",
        "with open('movie_club.txt', 'r') as f:\n",
        "  past_movie_club_emails = f.read()\n",
        "with open('running_club.txt', 'r') as f:\n",
        "  past_running_club_emails = f.read()\n",
        "with open('math_club.txt', 'r') as f:\n",
        "  past_math_club_emails = f.read()\n",
        "\n",
        "context = \"{{past_emails}}\\n\\nBased on the tone of past emails, write a very funny email about {{subject}} for the {{club_name}} club. Be sure to include a joke or witty pun.\" # double curly braces indicate a variable\n",
        "args=[\"past_emails\", \"subject\", \"club_name\"]\n",
        "template = ContextTemplate(context, args)\n",
        "\n",
        "llm = LLM(config)\n",
        "llm.fit(template)\n",
        "\n",
        "my_clubs_info = [\n",
        "    {\n",
        "      'name': 'movie',\n",
        "      'subjects': ['recruiting new members', 'the new harry potter fan fiction indie movie'],\n",
        "      'past_emails': past_movie_club_emails\n",
        "    },\n",
        "    {\n",
        "      'name': 'running',\n",
        "      'subjects': ['the team winning the meet', 'practice being still on despite the blizzard'],\n",
        "      'past_emails': past_running_club_emails\n",
        "    },\n",
        "    {\n",
        "      'name': 'math',\n",
        "      'subjects': ['competition practice', 'electing a new president for next semester'],\n",
        "      'past_emails': past_math_club_emails\n",
        "    }\n",
        "]\n",
        "\n",
        "for club in my_clubs_info:\n",
        "  my_club_name = club['name']\n",
        "  subjects = club['subjects']\n",
        "  past_emails = club['past_emails']\n",
        "\n",
        "  # Run your LLM, looping through your different clubs and subjects for them\n",
        "  for subject in subjects:\n",
        "    print(f'Email for {my_club_name} club about {subject}')\n",
        "    output = llm.predict(past_emails=past_emails, subject=subject, club_name=my_club_name)\n",
        "    print(output)\n",
        "    print(\"\\n--------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v6XeAkgz6t3"
      },
      "source": [
        "#### Great work! Hope you saw how small programmatic changes to the context for the LLM made sometimes drastic changes and improvements to how the LLM behaved. Now off to do more things with LLMs!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
